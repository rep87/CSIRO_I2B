{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# Cell 1: imports + paths/seeds/config\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import time\n",
        "import random\n",
        "import subprocess\n",
        "from typing import List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "from sklearn.metrics import r2_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Paths and run configuration\n",
        "DATA_ROOT = \"/kaggle/input/csiro-biomass\"\n",
        "OUTPUT_ROOT = \"/kaggle/working/outputs\"\n",
        "RUN_NAME = os.environ.get(\"RUN_NAME\", time.strftime(\"%Y%m%d-%H%M%S\"))\n",
        "RUN_DIR = os.path.join(OUTPUT_ROOT, RUN_NAME)\n",
        "SUBMISSION_PATH = os.path.join(RUN_DIR, \"submission\", \"submission.csv\")\n",
        "WORKING_SUBMISSION = \"/kaggle/working/submission.csv\"\n",
        "\n",
        "CONFIG = {\n",
        "    \"backbone\": os.environ.get(\"BACKBONE\", \"efficientnet_b2\"),\n",
        "    \"image_size\": int(os.environ.get(\"IMAGE_SIZE\", 456)),\n",
        "    \"batch_size\": int(os.environ.get(\"BATCH_SIZE\", 32)),\n",
        "    \"num_workers\": int(os.environ.get(\"NUM_WORKERS\", 2)),\n",
        "    \"epochs\": int(os.environ.get(\"EPOCHS\", 20)),\n",
        "    \"lr\": float(os.environ.get(\"LR\", 1e-3)),\n",
        "    \"weight_decay\": float(os.environ.get(\"WEIGHT_DECAY\", 1e-4)),\n",
        "    \"patience\": int(os.environ.get(\"PATIENCE\", 3)),\n",
        "    \"seed\": int(os.environ.get(\"SEED\", 42)),\n",
        "    \"folds\": int(os.environ.get(\"FOLDS\", 5)),\n",
        "    \"debug\": os.environ.get(\"DEBUG\", \"0\").lower() in {\"1\", \"true\", \"yes\", \"y\"},\n",
        "    \"accumulate_steps\": int(os.environ.get(\"ACCUM_STEPS\", 1)),\n",
        "    \"amp\": os.environ.get(\"AMP\", \"1\").lower() in {\"1\", \"true\", \"yes\", \"y\"},\n",
        "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "}\n",
        "\n",
        "TARGET_COLUMNS = [\"Dry_Green_g\", \"Dry_Clover_g\", \"Dry_Dead_g\"]\n",
        "ALL_TARGET_COLUMNS = TARGET_COLUMNS + [\"GDM_g\", \"Dry_Total_g\"]\n",
        "AGGREGATION_COLUMNS = [\"sample_id_prefix\", \"image_path\"]\n",
        "\n",
        "_INSTALL_ATTEMPTED = False\n",
        "\n",
        "\n",
        "def ensure_dirs() -> None:\n",
        "    os.makedirs(RUN_DIR, exist_ok=True)\n",
        "    for sub in [\"checkpoints\", \"preds\", \"submission\", \"logs\"]:\n",
        "        os.makedirs(os.path.join(RUN_DIR, sub), exist_ok=True)\n",
        "\n",
        "\n",
        "def set_seed(seed: int) -> None:\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "def ensure_timm_installed() -> None:\n",
        "    global _INSTALL_ATTEMPTED\n",
        "    try:\n",
        "        import timm  # noqa: F401\n",
        "        return\n",
        "    except ImportError:\n",
        "        if _INSTALL_ATTEMPTED:\n",
        "            raise SystemExit(\"timm is required but could not be installed.\")\n",
        "        _INSTALL_ATTEMPTED = True\n",
        "        print(\"timm not found; attempting installation once...\")\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"timm>=0.9.0\"])\n",
        "        except Exception as exc:  # pragma: no cover - Kaggle offline safety\n",
        "            print(\"timm installation failed. Please attach internet or add timm to the dataset.\")\n",
        "            raise SystemExit(exc)\n",
        "\n",
        "\n",
        "ensure_dirs()\n",
        "set_seed(CONFIG[\"seed\"])\n",
        "print(\"Using device:\", CONFIG[\"device\"])\n",
        "print(\"Run directory:\", RUN_DIR)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# Cell 2: data existence check + train/test columns\n",
        "train_csv = os.path.join(DATA_ROOT, \"train.csv\")\n",
        "test_csv = os.path.join(DATA_ROOT, \"test.csv\")\n",
        "sample_sub_csv = os.path.join(DATA_ROOT, \"sample_submission.csv\")\n",
        "\n",
        "print(\"Train CSV exists:\", os.path.exists(train_csv))\n",
        "print(\"Test CSV exists:\", os.path.exists(test_csv))\n",
        "print(\"Sample submission exists:\", os.path.exists(sample_sub_csv))\n",
        "\n",
        "train_images = glob.glob(os.path.join(DATA_ROOT, \"train\", \"*.jpg\"))\n",
        "test_images = glob.glob(os.path.join(DATA_ROOT, \"test\", \"*.jpg\"))\n",
        "print(f\"Detected train images: {len(train_images)}\")\n",
        "print(f\"Detected test images: {len(test_images)}\")\n",
        "\n",
        "train_head = pd.read_csv(train_csv, nrows=3)\n",
        "test_head = pd.read_csv(test_csv, nrows=3)\n",
        "print(\"Train columns:\", train_head.columns.tolist())\n",
        "print(\"Test columns:\", test_head.columns.tolist())\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# Cell 3: data loading + long\u2192wide aggregation\n",
        "\n",
        "def load_long_dataframe(csv_path: str, include_targets: bool = True) -> pd.DataFrame:\n",
        "    df = pd.read_csv(csv_path)\n",
        "    if \"sample_id\" not in df.columns or \"image_path\" not in df.columns:\n",
        "        raise ValueError(\"CSV must contain sample_id and image_path columns\")\n",
        "    df[\"sample_id_prefix\"] = df[\"sample_id\"].astype(str).str.split(\"__\").str[0]\n",
        "    if include_targets:\n",
        "        missing = [c for c in [\"target_name\", \"target\"] if c not in df.columns]\n",
        "        if missing:\n",
        "            raise ValueError(f\"Missing target columns in training data: {missing}\")\n",
        "    return df\n",
        "\n",
        "\n",
        "def to_wide(df: pd.DataFrame, include_targets: bool = True) -> pd.DataFrame:\n",
        "    index_cols = [c for c in AGGREGATION_COLUMNS if c in df.columns]\n",
        "    missing_idx = [c for c in AGGREGATION_COLUMNS if c not in index_cols]\n",
        "    if missing_idx:\n",
        "        raise ValueError(f\"Missing required aggregation columns: {missing_idx}\")\n",
        "    print(\"Aggregation columns:\", index_cols)\n",
        "\n",
        "    if not include_targets:\n",
        "        return df[index_cols].drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "    pivot = df.pivot_table(index=index_cols, columns=\"target_name\", values=\"target\", aggfunc=\"first\").reset_index()\n",
        "    missing_targets = [c for c in TARGET_COLUMNS if c not in pivot.columns]\n",
        "    if missing_targets:\n",
        "        raise ValueError(f\"Missing target columns after pivot: {missing_targets}\")\n",
        "    pivot = pivot[index_cols + TARGET_COLUMNS]\n",
        "    return pivot\n",
        "\n",
        "\n",
        "train_long = load_long_dataframe(train_csv, include_targets=True)\n",
        "test_long = load_long_dataframe(test_csv, include_targets=False)\n",
        "\n",
        "train_wide = to_wide(train_long, include_targets=True)\n",
        "test_wide = to_wide(test_long, include_targets=False)\n",
        "\n",
        "if CONFIG[\"debug\"]:\n",
        "    train_wide = train_wide.sample(n=min(len(train_wide), 32), random_state=CONFIG[\"seed\"])\n",
        "    test_wide = test_wide.head(8)\n",
        "    print(\"DEBUG mode: subsampled train and test data\")\n",
        "\n",
        "print(\"Train wide shape:\", train_wide.shape)\n",
        "print(\"Test wide shape:\", test_wide.shape)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# Cell 4: Dataset and transforms\n",
        "\n",
        "def build_transforms(image_size: int, augment: bool) -> T.Compose:\n",
        "    if augment:\n",
        "        return T.Compose([\n",
        "            T.Resize((image_size, image_size)),\n",
        "            T.RandomHorizontalFlip(),\n",
        "            T.RandomVerticalFlip(),\n",
        "            T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.02),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "    else:\n",
        "        return T.Compose([\n",
        "            T.Resize((image_size, image_size)),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "\n",
        "\n",
        "class RegressionDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, image_size: int, augment: bool = False, use_targets: bool = True):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = build_transforms(image_size, augment)\n",
        "        self.use_targets = use_targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = os.path.normpath(os.path.join(DATA_ROOT, row[\"image_path\"]))\n",
        "        with Image.open(img_path) as img:\n",
        "            image = img.convert(\"RGB\")\n",
        "        image = self.transform(image)\n",
        "\n",
        "        if self.use_targets:\n",
        "            targets = torch.tensor(row[TARGET_COLUMNS].values.astype(\"float32\"))\n",
        "        else:\n",
        "            targets = torch.zeros(len(TARGET_COLUMNS), dtype=torch.float32)\n",
        "        return image, targets, row.get(\"sample_id_prefix\", None)\n",
        "\n",
        "\n",
        "def create_dataloaders(df: pd.DataFrame, train_idx: List[int], val_idx: List[int]) -> Tuple[DataLoader, DataLoader]:\n",
        "    train_ds = RegressionDataset(df.iloc[train_idx], CONFIG[\"image_size\"], augment=True, use_targets=True)\n",
        "    val_ds = RegressionDataset(df.iloc[val_idx], CONFIG[\"image_size\"], augment=False, use_targets=True)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=CONFIG[\"batch_size\"], shuffle=True, num_workers=CONFIG[\"num_workers\"], pin_memory=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=CONFIG[\"batch_size\"], shuffle=False, num_workers=CONFIG[\"num_workers\"], pin_memory=True)\n",
        "    return train_loader, val_loader\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# Cell 5: Model definition (timm efficientnet_b2)\n",
        "\n",
        "def build_model(pretrained: bool = True) -> nn.Module:\n",
        "    ensure_timm_installed()\n",
        "    import timm\n",
        "    model = timm.create_model(CONFIG[\"backbone\"], pretrained=pretrained, num_classes=len(TARGET_COLUMNS))\n",
        "    return model\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# Cell 6: Metrics (weighted R2)\n",
        "\n",
        "def compute_weighted_r2(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
        "    weights = np.ones(y_true.shape[1], dtype=np.float32)\n",
        "    scores = []\n",
        "    for i in range(y_true.shape[1]):\n",
        "        if np.all(np.isclose(y_true[:, i], y_true[0, i])):\n",
        "            scores.append(0.0)\n",
        "        else:\n",
        "            scores.append(r2_score(y_true[:, i], y_pred[:, i]))\n",
        "    scores = np.array(scores)\n",
        "    return float(np.sum(scores * weights) / np.sum(weights))\n",
        "\n",
        "\n",
        "def expand_targets(primary: np.ndarray) -> np.ndarray:\n",
        "    dry_green = primary[:, 0]\n",
        "    dry_clover = primary[:, 1]\n",
        "    dry_dead = primary[:, 2]\n",
        "    gdm = dry_green + dry_clover\n",
        "    dry_total = gdm + dry_dead\n",
        "    full = np.stack([dry_green, dry_dead, dry_clover, gdm, dry_total], axis=1)\n",
        "    return full\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# Cell 7: Train loop + 5-fold CV + checkpoint saving\n",
        "\n",
        "def evaluate(model: nn.Module, loader: DataLoader, device: torch.device) -> float:\n",
        "    model.eval()\n",
        "    preds_list = []\n",
        "    targets_list = []\n",
        "    with torch.no_grad():\n",
        "        for images, targets, _ in loader:\n",
        "            images = images.to(device)\n",
        "            targets = targets.to(device)\n",
        "            outputs = model(images)\n",
        "            preds_list.append(outputs.cpu().numpy())\n",
        "            targets_list.append(targets.cpu().numpy())\n",
        "    preds = np.concatenate(preds_list)\n",
        "    targets = np.concatenate(targets_list)\n",
        "    preds_full = expand_targets(preds)\n",
        "    targets_full = expand_targets(targets)\n",
        "    return compute_weighted_r2(targets_full, preds_full)\n",
        "\n",
        "\n",
        "def train_and_validate(df: pd.DataFrame) -> float:\n",
        "    device = torch.device(CONFIG[\"device\"] if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Training on device:\", device)\n",
        "\n",
        "    num_samples = len(df)\n",
        "    fold_size = num_samples // CONFIG[\"folds\"]\n",
        "    indices = np.arange(num_samples)\n",
        "    best_scores: List[float] = []\n",
        "\n",
        "    for fold in range(CONFIG[\"folds\"]):\n",
        "        print(f\"=== Fold {fold + 1} / {CONFIG['folds']} ===\")\n",
        "        val_start = fold * fold_size\n",
        "        val_end = (fold + 1) * fold_size if fold < CONFIG[\"folds\"] - 1 else num_samples\n",
        "        val_idx = indices[val_start:val_end]\n",
        "        train_idx = np.concatenate([indices[:val_start], indices[val_end:]])\n",
        "\n",
        "        train_loader, val_loader = create_dataloaders(df, train_idx.tolist(), val_idx.tolist())\n",
        "\n",
        "        model = build_model(pretrained=True).to(device)\n",
        "        criterion = nn.SmoothL1Loss()\n",
        "        optimizer = AdamW(model.parameters(), lr=CONFIG[\"lr\"], weight_decay=CONFIG[\"weight_decay\"])\n",
        "        scheduler = ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.5, patience=CONFIG[\"patience\"])\n",
        "        scaler = GradScaler(enabled=CONFIG[\"amp\"])\n",
        "\n",
        "        best_fold_score = -np.inf\n",
        "        best_path = os.path.join(RUN_DIR, \"checkpoints\", f\"fold{fold}_best.pth\")\n",
        "        last_path = os.path.join(RUN_DIR, \"checkpoints\", f\"fold{fold}_last.pth\")\n",
        "\n",
        "        for epoch in range(CONFIG[\"epochs\"]):\n",
        "            model.train()\n",
        "            running_loss = 0.0\n",
        "            pbar = tqdm(train_loader, desc=f\"Fold {fold} Epoch {epoch+1}/{CONFIG['epochs']}\")\n",
        "            optimizer.zero_grad()\n",
        "            for step, (images, targets, _) in enumerate(pbar):\n",
        "                images = images.to(device)\n",
        "                targets = targets.to(device)\n",
        "\n",
        "                with autocast(enabled=CONFIG[\"amp\"]):\n",
        "                    preds = model(images)\n",
        "                    loss = criterion(preds, targets) / CONFIG[\"accumulate_steps\"]\n",
        "\n",
        "                scaler.scale(loss).backward()\n",
        "\n",
        "                if (step + 1) % CONFIG[\"accumulate_steps\"] == 0:\n",
        "                    scaler.step(optimizer)\n",
        "                    scaler.update()\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                running_loss += loss.item() * CONFIG[\"accumulate_steps\"]\n",
        "                pbar.set_postfix({\"loss\": running_loss / (step + 1)})\n",
        "\n",
        "            val_score = evaluate(model, val_loader, device)\n",
        "            print(f\"Epoch {epoch + 1} loss {running_loss / len(train_loader):.4f} val_r2 {val_score:.4f}\")\n",
        "            scheduler.step(val_score)\n",
        "\n",
        "            torch.save(model.state_dict(), last_path)\n",
        "            if val_score > best_fold_score:\n",
        "                best_fold_score = val_score\n",
        "                torch.save(model.state_dict(), best_path)\n",
        "        best_scores.append(best_fold_score)\n",
        "    mean_score = float(np.mean(best_scores))\n",
        "    print(f\"CV mean R2: {mean_score:.4f}\")\n",
        "    return mean_score\n",
        "\n",
        "\n",
        "cv_score = train_and_validate(train_wide)\n",
        "print(\"Training complete. CV score:\", cv_score)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# Cell 8: Inference + submission generation\n",
        "\n",
        "def predict_wide(test_df: pd.DataFrame, device: torch.device) -> np.ndarray:\n",
        "    ds = RegressionDataset(test_df, CONFIG[\"image_size\"], augment=False, use_targets=False)\n",
        "    loader = DataLoader(ds, batch_size=CONFIG[\"batch_size\"], shuffle=False, num_workers=CONFIG[\"num_workers\"], pin_memory=True)\n",
        "\n",
        "    ckpt_dir = os.path.join(RUN_DIR, \"checkpoints\")\n",
        "    ckpts = sorted([os.path.join(ckpt_dir, p) for p in os.listdir(ckpt_dir) if p.endswith(\"_best.pth\")])\n",
        "    if not ckpts:\n",
        "        raise FileNotFoundError(\"No checkpoints found for inference\")\n",
        "\n",
        "    preds_stack: List[np.ndarray] = []\n",
        "    for ckpt_path in ckpts:\n",
        "        model = build_model(pretrained=False)\n",
        "        state = torch.load(ckpt_path, map_location=device)\n",
        "        model.load_state_dict(state)\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "\n",
        "        fold_preds = []\n",
        "        with torch.no_grad():\n",
        "            for images, _, _ in tqdm(loader, desc=f\"Infer {os.path.basename(ckpt_path)}\"):\n",
        "                images = images.to(device)\n",
        "                outputs = model(images)\n",
        "                fold_preds.append(outputs.cpu().numpy())\n",
        "        preds_stack.append(np.concatenate(fold_preds))\n",
        "\n",
        "    preds_mean = np.mean(preds_stack, axis=0)\n",
        "    return preds_mean\n",
        "\n",
        "\n",
        "def build_submission(test_long_df: pd.DataFrame, test_wide_df: pd.DataFrame, preds: np.ndarray) -> pd.DataFrame:\n",
        "    full_preds = expand_targets(preds)\n",
        "    pred_df = pd.DataFrame(full_preds, columns=[\"Dry_Green_g\", \"Dry_Dead_g\", \"Dry_Clover_g\", \"GDM_g\", \"Dry_Total_g\"])\n",
        "    pred_df[\"sample_id_prefix\"] = test_wide_df[\"sample_id_prefix\"].values\n",
        "\n",
        "    pred_long = pred_df.melt(id_vars=\"sample_id_prefix\", var_name=\"target_name\", value_name=\"target\")\n",
        "    pred_long[\"sample_id\"] = pred_long[\"sample_id_prefix\"].astype(str) + \"__\" + pred_long[\"target_name\"].astype(str)\n",
        "\n",
        "    merged = test_long_df.merge(pred_long[[\"sample_id_prefix\", \"target_name\", \"target\"]], on=[\"sample_id_prefix\", \"target_name\"], how=\"left\", sort=False)\n",
        "    submission = merged[[\"sample_id\", \"target\"]].copy()\n",
        "    return submission\n",
        "\n",
        "\n",
        "def run_inference_and_save():\n",
        "    device = torch.device(CONFIG[\"device\"] if torch.cuda.is_available() else \"cpu\")\n",
        "    preds_mean = predict_wide(test_wide, device)\n",
        "    submission = build_submission(test_long, test_wide, preds_mean)\n",
        "    submission.to_csv(SUBMISSION_PATH, index=False)\n",
        "\n",
        "    os.makedirs(os.path.dirname(WORKING_SUBMISSION), exist_ok=True)\n",
        "    submission.to_csv(WORKING_SUBMISSION, index=False)\n",
        "    print(\"Submission saved to:\", SUBMISSION_PATH)\n",
        "    print(\"Working copy:\", WORKING_SUBMISSION)\n",
        "    return submission\n",
        "\n",
        "\n",
        "submission_df = run_inference_and_save()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# Cell 9: Submission validation + file locations\n",
        "print(\"Submission preview:\")\n",
        "print(submission_df.head())\n",
        "print(\"Submission shape:\", submission_df.shape)\n",
        "print(\"Submission columns:\", submission_df.columns.tolist())\n",
        "print(\"NaN present:\", submission_df[\"target\"].isna().any())\n",
        "\n",
        "if os.path.exists(sample_sub_csv):\n",
        "    sample_sub = pd.read_csv(sample_sub_csv)\n",
        "    sample_ids = set(sample_sub[\"sample_id\"])\n",
        "    submission_ids = set(submission_df[\"sample_id\"])\n",
        "    missing_ids = sample_ids - submission_ids\n",
        "    extra_ids = submission_ids - sample_ids\n",
        "    print(\"Missing IDs vs sample_submission:\", len(missing_ids))\n",
        "    print(\"Extra IDs vs sample_submission:\", len(extra_ids))\n",
        "else:\n",
        "    print(\"sample_submission.csv not found; skipping ID comparison\")\n",
        "\n",
        "print(\"Artifacts saved under:\", RUN_DIR)\n",
        "print(\"Primary submission file:\", SUBMISSION_PATH)\n",
        "print(\"Working submission copy:\", WORKING_SUBMISSION)\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}